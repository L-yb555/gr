ICLR:https://github.com/yinizhilian/ICLR2025-Papers-with-Code?tab=readme-ov-file#accept-spotlight

2021-2024无


ICML 2023-2024  https://github.com/yinizhilian/ICML2025-Papers-with-Code
 Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition
- Paper: [**点击下载**](https://openreview.net/attachment?id=SQtp4uUByd&name=pdf)
- Code: [https://github.com/OSVAI/Ske2Grid](https://github.com/OSVAI/Ske2Grid)
-
- Taylor Videos for Action Recognition
- Paper: [**点击下载**](https://openreview.net/attachment?id=chhIZGqlUG&name=pdf)
- Code: [https://github.com/LeiWangR/video-ar](https://github.com/LeiWangR/video-ar)

EMNL 2022-2024  https://improved-goldfish-v6qrq5x9v4wv2xqvg.github.dev/
  Learning Co-Speech Gesture for Multimodal Aphasia Type Detection
- Paper: [**点击下载**](https://arxiv.org/pdf/2310.11710.pdf)
- Code: [https://github.com/DSAIL-SKKU/Multimodal-Aphasia-Type-Detection_EMNLP_2023](https://github.com/DSAIL-SKKU/Multimodal-Aphasia-Type-Detection_EMNLP_2023)


CVPR 2020-2025
 *An Efficient PointLSTM for Point Clouds Based Gesture Recognition**
- 论文：http://openaccess.thecvf.com/content_CVPR_2020/html/
- Min_An_Efficient_PointLSTM_for_Point_Clouds_Based_Gesture_Recognition_CVPR_2020_paper.html
- 代码：https://github.com/Blueprintf/pointlstm-gesture-recognition-pytorch
- 
Improved Handling of Motion Blur in Online Object Detection(改进在线对象检测中运动模糊的处理)<br>
[paper](https://arxiv.org/abs/2011.14448)<br><br>

Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive  2D-1D Registration(基于语义聚合和自适应2D-1D配准的相机空间手部网格恢复)<br>
[paper](https://arxiv.org/pdf/2103.02845.pdf) | [code](https://github.com/SeanChenxy/HandMesh)<br><br>

DexYCB: A Benchmark for Capturing Hand Grasping of Objects(DexYCB：捕获对象的手抓握的基准)<br>
[paper](https://arxiv.org/abs/2104.04631) |[dataset&code](https://dex-ycb.github.io/)

 ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis(通过在线探索和合成提升关节式 3D 手对象姿势估计)<br>
[paper](https://arxiv.org/abs/2109.05488) | [code](https://github.com/lixiny/ArtiBoost)<br><br>

 Joint Hand Motion and Interaction Hotspots Prediction from Egocentric Videos(以自我为中心的视频的联合手部运动和交互热点预测)<br>
[paper](https://arxiv.org/abs/2204.01696) | [project](https://stevenlsw.github.io/hoi-forecast)<br><br>

OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction(理解手物交互的大规模知识库)<br>
[paper](https://arxiv.org/abs/2203.15709) | [datasets&code](https://github.com/lixiny/OakInk)<br><br>

A2J-Transformer: Anchor-to-Joint Transformer Network for 3D Interacting Hand Pose Estimation from a Single RGB Image<br>
[paper](https://arxiv.org/abs/2304.03635) | [code](https://github.com/changlongjianggit/a2j-transformer)<br><br>

CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis<br>
[paper](https://arxiv.org/abs/2303.15469)<br><br>

Bringing Inputs to Shared Domains for 3D Interacting Hands Recovery in the Wild<br>
[paper](https://arxiv.org/abs/2303.13652)<br><br>

Natural Language-Assisted Sign Language Recognition<br>
[paper](https://arxiv.org/abs/2303.12080) | [code](https://github.com/FangyunWei/SLRT)<br><br>

CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition with Variational Alignment<br>
[paper](https://arxiv.org/abs/2303.05725) | [code](https://arxiv.org/abs/2303.05725)<br><br>

Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement<br>
[paper](https://arxiv.org/abs/2303.01765)<br><br>

Hierarchical Temporal Transformer for 3D Hand Pose Estimation and Action Recognition from Egocentric RGB Videos<br>
[paper](https://arxiv.org/abs/2209.09484) | [code](https://github.com/fylwen/htt)<br><br>

[20]Learning Human-to-Robot Handovers from Point Clouds<br>
[paper](https://arxiv.org/abs/2303.17592)<br><br>

Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes<br>
[paper](https://arxiv.org/abs/2302.14348) | [code](https://github.com/jyunlee/Im2Hands)<br><br>
[16]Recovering 3D Hand Mesh Sequence from a Single Blurry Image: A New Dataset and Temporal Unfolding<br>
[paper](https://arxiv.org/abs/2303.15417) | [code](https://github.com/jaehakim97/blurhand_release)<br><br>

A Neural Network Based on SPD Manifold Learning for Skeleton-Based Hand Gesture Recognition
[paper]https://arxiv.org/pdf/1904.12970
Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition With Multimodal Training
[paper]https://arxiv.org/pdf/1812.06145
Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition with Multimodal Training,Mahdi Abavisani
[paper]https://arxiv.org/pdf/1812.06145
A neural network based on SPD manifold learning for skeleton-based hand gesture recognition
[paper]https://arxiv.org/pdf/1904.12970
Gesture Recognition: Focus on the Hands,,"Pradyumna Narayana, Colorado State University
[paper]https://openaccess.thecvf.com/content_cvpr_2018/papers/Narayana_Gesture_Recognition_Focus_CVPR_2018_paper.pdf


ICCV



ECCV

science advances 
搜索 gesture recognition 基本是材料
![image](https://github.com/user-attachments/assets/488bd507-2742-4f65-9f82-a1e734b0c009)

nature communation/machine intelligence 
基本无视觉，有semg 大部分都是从材料做，基本是数据集才有代码,下面是检索的图片，里面有的文章，都没找到代码
![image](https://github.com/user-attachments/assets/c19e0e47-7f5b-440e-9969-b6af357b0371)

IEE TPMI
搜索gesture recognition 2020-2024 总共就十几篇，相关一点3篇，没代码，其中有两篇再CVPR上发布过
![image](https://github.com/user-attachments/assets/7598b025-1819-48bd-8780-5a8a43d897d1)
https://webvpn.jiangnan.edu.cn/https/77726476706e69737468656265737421f9f244993f20645f6c0dc7a59d50267b1ab4a9/stamp/stamp.jsp?tp=&arnumber=9681230
https://webvpn.jiangnan.edu.cn/https/77726476706e69737468656265737421f9f244993f20645f6c0dc7a59d50267b1ab4a9/stamp/stamp.jsp?tp=&arnumber=10478195
https://webvpn.jiangnan.edu.cn/https/77726476706e69737468656265737421f9f244993f20645f6c0dc7a59d50267b1ab4a9/stamp/stamp.jsp?tp=&arnumber=8691602


